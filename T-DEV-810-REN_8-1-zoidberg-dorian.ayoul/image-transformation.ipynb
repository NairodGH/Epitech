{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Subset\n",
    "from torchvision.transforms import functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import ImageFilter\n",
    "\n",
    "class Denoise:\n",
    "    def __call__(self, img):\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=1))\n",
    "        return img\n",
    "\n",
    "class HistogramEqualization:\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.equalizeHist(img)\n",
    "        return F.to_pil_image(img)\n",
    "\n",
    "\n",
    "def load_data(path, subset_size=624, batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        # HistogramEqualization(),\n",
    "        # Denoise(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "    ])\n",
    "\n",
    "    dataset_folder = ImageFolder(root=path, transform=transform)\n",
    "    subset = Subset(dataset_folder, range(subset_size))\n",
    "    dataset = DataLoader(subset, batch_size=batch_size)\n",
    "\n",
    "    # print('Dataset\\t', 'Train\\t', dataset_folder.classes[0], '', dataset_folder.classes[1])\n",
    "    # print('Total:\\t', len(dataset_folder), '\\t', dataset_folder.targets.count(0), '\\t', dataset_folder.targets.count(1))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "def save_transformed_images(dataset, path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    for i, (image, label) in enumerate(tqdm(dataset)):\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        image.save(os.path.join(path, f'imagey_{i}_label_{label}.png'))\n",
    "\n",
    "data_path = 'datasets/train'\n",
    "\n",
    "dataset = load_data(path=data_path, subset_size=1, batch_size=64)\n",
    "\n",
    "save_transformed_images(dataset.dataset, 'datasets/lol/NORMAL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
